{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conll 2003 evaluation\n",
    "\n",
    "Data downloaded from [here](https://github.com/kyzhouhzau/BERT-NER/tree/master/NERdata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/datadrive/conll-2003/\"\n",
    "\n",
    "train_path = data_path + \"train.txt\"\n",
    "dev_path = data_path + \"dev.txt\"\n",
    "test_path = data_path + \"test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prc data for csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"Reads a BIO data.\"\"\"\n",
    "    with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = []\n",
    "        words = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            contends = line.strip()\n",
    "            word = line.strip().split(' ')[0]\n",
    "            label = line.strip().split(' ')[-1]\n",
    "            if contends.startswith(\"-DOCSTART-\"):\n",
    "                words.append('')\n",
    "                continue\n",
    "            \n",
    "            if len(contends) == 0 and not len(words):\n",
    "                words.append(\"\")\n",
    "            \n",
    "            if len(contends) == 0 and words[-1] == '.':\n",
    "                l = ' '.join([label for label in labels if len(label) > 0])\n",
    "                w = ' '.join([word for word in words if len(word) > 0])\n",
    "                lines.append([l, w])\n",
    "                words = []\n",
    "                labels = []\n",
    "                continue\n",
    "            words.append(word)\n",
    "            labels.append(label.replace(\"-\", \"_\"))\n",
    "        return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = read_data(train_path)\n",
    "dev_f = read_data(dev_path)\n",
    "test_f = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[l for l in train_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 1739, 1559)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_f), len(dev_f), len(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_ORG O B_MISC O O O B_MISC O O',\n",
       " 'EU rejects German call to boycott British lamb .']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_f, columns=[\"0\", \"1\"])\n",
    "train_df.to_csv(data_path + \"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame(dev_f, columns=[\"0\", \"1\"])\n",
    "valid_df.to_csv(data_path + \"valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_f, columns=[\"0\", \"1\"])\n",
    "test_df.to_csv(data_path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/datadrive/conll-2003/\"\n",
    "train_path = data_path + \"train.csv\"\n",
    "valid_path = data_path + \"valid.csv\"\n",
    "test_path = data_path + \"test.csv\"\n",
    "\n",
    "model_dir = \" /datadrive/models/multi_cased_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = os.path.join(\"/datadrive/models/multi_cased_L-12_H-768_A-12/\", \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"bert_config.json\")\n",
    "vocab_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.is_available(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from modules import NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 1739)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dl.dataset), len(data.valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '[CLS]', '[SEP]', 'B_ORG', 'B_O', 'I_O', 'B_MISC', 'B_PER', 'I_PER', 'B_LOC', 'I_LOC', 'I_ORG', 'I_MISC']\n"
     ]
    }
   ],
   "source": [
    "print(data.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_labels = ['B_ORG', 'B_MISC', 'B_PER', 'I_PER', 'B_LOC', 'I_LOC', 'I_ORG', 'I_MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(f.labels_ids) for f in data.train_dl.dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.models import BertBiLSTMAttnCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertBiLSTMAttnCRF.create(len(data.label2idx), bert_config_file, init_checkpoint_pt, enc_hidden_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151739"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: fix bug with len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Use lr OneCycleScheduler...\n"
     ]
    }
   ],
   "source": [
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/models/conll-2003/bilstm_attn_cased.cpt\",\n",
    "                     base_lr=0.0001, lr_max=0.005, clip=5.0, use_lr_scheduler=True, sup_labels=sup_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Start learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(25, target_metric='prec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.data import get_bert_data_loader_for_predict\n",
    "dl = get_bert_data_loader_for_predict(data_path + \"valid.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.917     0.924     0.920      1282\n",
      "      B_MISC      0.925     0.864     0.894       905\n",
      "       B_PER      0.971     0.976     0.973      1686\n",
      "       I_PER      0.981     0.970     0.976      3488\n",
      "       B_LOC      0.966     0.950     0.958      1669\n",
      "       I_LOC      0.957     0.909     0.932      1913\n",
      "       I_ORG      0.922     0.888     0.905      2129\n",
      "      I_MISC      0.920     0.675     0.779      1061\n",
      "\n",
      "   micro avg      0.953     0.915     0.933     14133\n",
      "   macro avg      0.945     0.894     0.917     14133\n",
      "weighted avg      0.952     0.915     0.932     14133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC      0.892     0.877     0.885      1669\n",
      "         ORG      0.828     0.832     0.830      1282\n",
      "           O      0.988     0.990     0.989     41846\n",
      "        MISC      0.899     0.840     0.869       905\n",
      "         PER      0.934     0.938     0.936      1686\n",
      "\n",
      "   micro avg      0.977     0.977     0.977     47388\n",
      "   macro avg      0.908     0.895     0.902     47388\n",
      "weighted avg      0.977     0.977     0.977     47388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds, [])\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.data import get_bert_data_loader_for_predict\n",
    "dl = get_bert_data_loader_for_predict(data_path + \"test.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.917     0.924     0.920      1282\n",
      "      B_MISC      0.925     0.864     0.894       905\n",
      "       B_PER      0.971     0.976     0.973      1686\n",
      "       I_PER      0.981     0.970     0.976      3488\n",
      "       B_LOC      0.966     0.950     0.958      1669\n",
      "       I_LOC      0.957     0.909     0.932      1913\n",
      "       I_ORG      0.922     0.888     0.905      2129\n",
      "      I_MISC      0.920     0.675     0.779      1061\n",
      "\n",
      "   micro avg      0.953     0.915     0.933     14133\n",
      "   macro avg      0.945     0.894     0.917     14133\n",
      "weighted avg      0.952     0.915     0.932     14133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC      0.864     0.851     0.858      1570\n",
      "         ORG      0.714     0.721     0.717      1533\n",
      "           O      0.981     0.983     0.982     37683\n",
      "        MISC      0.820     0.753     0.785       688\n",
      "         PER      0.911     0.901     0.906      1566\n",
      "\n",
      "   micro avg      0.963     0.963     0.963     43040\n",
      "   macro avg      0.858     0.842     0.850     43040\n",
      "weighted avg      0.962     0.963     0.962     43040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds, [])\n",
    "print(clf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
